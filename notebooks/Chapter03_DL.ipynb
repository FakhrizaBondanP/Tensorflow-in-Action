{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a910b3e4-b390-4751-9f05-a8e9f6ce14c4",
   "metadata": {},
   "source": [
    "# üß± Keras & Data Pipelines (TensorFlow 2)\n",
    "**Source: TensorFlow in Action ‚Äì Chapter 3: Keras and data retrieval in TensorFlow 2**\n",
    "\n",
    "Chapter 3 membahas cara membangun model dengan Keras (Sequential, Functional, Sub-classing API) dan cara men-*stream* data ke model menggunakan `tf.data`, Keras `ImageDataGenerator`, serta paket `tensorflow-datasets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3244c49c-887f-430e-9dc7-64f4ae828389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d9bf3-df7f-4cc9-b784-62f1c5d819b6",
   "metadata": {},
   "source": [
    "## üß© Keras Model-Building APIs\n",
    "\n",
    "**Theory**: Keras yang terintegrasi di TensorFlow menyediakan tiga cara utama membangun model:\n",
    "\n",
    "- **Sequential API**: untuk arsitektur linear (satu input ‚Üí lapisan berurutan ‚Üí satu output).\n",
    "- **Functional API**: untuk arsitektur kompleks (multi-input, cabang paralel, multi-output).\n",
    "- **Sub-classing API**: untuk layer/model kustom dengan logika forward pass sendiri.\n",
    "\n",
    "Setiap API punya trade-off antara kemudahan penulisan dan fleksibilitas desain arsitektur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f99b9a-7f35-4c40-af8a-6ee0274183ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     sepallength  sepalwidth  petalwidth  petallength\n",
       " 31     -0.443333       0.346   -2.258667    -0.798667\n",
       " 23     -0.743333       0.246   -2.058667    -0.698667\n",
       " 70      0.056667       0.146    1.041333     0.601333\n",
       " 100     0.456667       0.246    2.241333     1.301333\n",
       " 44     -0.743333       0.746   -1.858667    -0.798667,\n",
       " TensorShape([150, 3]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Download Iris dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "r = requests.get(url)\n",
    "with open(\"iris.data\", \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "# Load ke pandas\n",
    "iris_df = pd.read_csv(\"iris.data\", header=None)\n",
    "iris_df.columns = [\"sepallength\", \"sepalwidth\", \"petalwidth\", \"petallength\", \"label\"]\n",
    "\n",
    "# Map label string ‚Üí int\n",
    "iris_df[\"label\"] = iris_df[\"label\"].map({\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 2\n",
    "})\n",
    "\n",
    "# Shuffle dan centering fitur\n",
    "iris_df = iris_df.sample(frac=1.0, random_state=4321)\n",
    "X = iris_df[[\"sepallength\", \"sepalwidth\", \"petalwidth\", \"petallength\"]]\n",
    "X = X - X.mean(axis=0)\n",
    "y = tf.one_hot(iris_df[\"label\"], depth=3)\n",
    "\n",
    "X.head(), y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e2d0c-cf4f-4c09-b8ac-3ea20516f6f8",
   "metadata": {},
   "source": [
    "## üîó Model A ‚Äì Sequential API\n",
    "\n",
    "**Theory**: Sequential API cocok untuk model yang benar-benar berurutan: satu input, beberapa hidden layer `Dense`, dan satu output.\n",
    "\n",
    "Setiap layer `Dense` menghitung\n",
    "$\n",
    "h = \\phi(XW + b)\n",
    "$\n",
    "di mana \\(X\\) adalah input, \\(W\\) bobot, \\(b\\) bias, dan \\(\\phi\\) fungsi aktivasi (misalnya ReLU atau softmax untuk output klasifikasi).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2775c505-2f9e-4132-93e7-1be7b5c64180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 739\n",
      "Trainable params: 739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model_a = Sequential([\n",
    "    Dense(32, activation=\"relu\", input_shape=(4,)),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_a.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_a.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f30a9dd-a285-4466-ad22-cbad4c641c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8199999928474426, 0.5480183959007263)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_a = model_a.fit(\n",
    "    X.values,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=25,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "history_a.history[\"accuracy\"][-1], history_a.history[\"loss\"][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe244d63-8940-43b5-bdd9-c8c2ae1011c4",
   "metadata": {},
   "source": [
    "## üåø Model B ‚Äì Functional API + PCA\r\n",
    "\r\n",
    "**Theory**: Functional API memudahkan pembuatan arsitektur model dengan beberapa input,\r\n",
    "misalnya input berupa fitur mentah dan input berupa fitur hasil PCA yang kemudian\r\n",
    "digabungkan (*concatenate*) sebelum diproses oleh layer lanjutan.\r\n",
    "\r\n",
    "Misalkan terdapat dua representasi tersembunyi dari dua input berbeda, yaitu:\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{h}_1 \\quad \\text{dan} \\quad \\mathbf{h}_2\r\n",
    "$$\r\n",
    "\r\n",
    "Kedua representasi tersebut dapat digabungkan menggunakan operasi konkatenasi\r\n",
    "sehingga diperoleh representasi baru:\r\n",
    "\r\n",
    "$$\r\n",
    "\\mathbf{h} = \\text{concat}(\\mathbf{h}_1, \\mathbf{h}_2)\r\n",
    "$$\r\n",
    "\r\n",
    "Hasil penggabungan ini selanjutnya diteruskan ke layer Dense berikutnya\r\n",
    "untuk proses pembelajaran lebih lanjut.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8bdc6d-11e8-4858-8c4c-ced7d6b9381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " raw_features (InputLayer)      [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " pca_features (InputLayer)      [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           80          ['raw_features[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           48          ['pca_features[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32)           0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           528         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 3)            51          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 707\n",
      "Trainable params: 707\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "\n",
    "# PCA 2 komponen pertama\n",
    "pca_model = PCA(n_components=2, random_state=4321)\n",
    "X_pca = pca_model.fit_transform(X.values)\n",
    "\n",
    "# Functional API\n",
    "K.clear_session()\n",
    "\n",
    "inp_raw = Input(shape=(4,), name=\"raw_features\")\n",
    "inp_pca = Input(shape=(2,), name=\"pca_features\")\n",
    "\n",
    "h1 = Dense(16, activation=\"relu\")(inp_raw)\n",
    "h2 = Dense(16, activation=\"relu\")(inp_pca)\n",
    "\n",
    "h_concat = Concatenate(axis=1)([h1, h2])\n",
    "h = Dense(16, activation=\"relu\")(h_concat)\n",
    "out = Dense(3, activation=\"softmax\")(h)\n",
    "\n",
    "model_b = models.Model(inputs=[inp_raw, inp_pca], outputs=out)\n",
    "model_b.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_b.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64817d82-9761-4c9a-9410-b7fed59e2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6866666674613953, 0.8173895478248596)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_b = model_b.fit(\n",
    "    [X.values, X_pca],\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "history_b.history[\"accuracy\"][-1], history_b.history[\"loss\"][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733c2cb-d86e-4ee8-a402-8615a5664816",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Model C ‚Äì Custom Layer (Sub-classing API)\n",
    "\n",
    "**Theory**: Sub-classing API digunakan ketika diperlukan pembuatan layer kustom\n",
    "dengan formulasi yang berbeda dari layer `Dense` standar. Pendekatan ini\n",
    "memberikan fleksibilitas penuh dalam mendefinisikan perilaku layer, baik dari\n",
    "sisi parameter maupun proses komputasinya.\n",
    "\n",
    "Pada contoh yang dibahas, fungsi hidden layer dimodifikasi menjadi:\n",
    "\n",
    "$$\n",
    "h = \\phi(XW + b + b_{\\text{mul}})\n",
    "$$\n",
    "\n",
    "di mana \\(W\\) merupakan bobot, \\(b\\) adalah bias utama, dan \\(b_{\\text{mul}}\\)\n",
    "merupakan *multiplicative bias* tambahan yang ikut dipelajari selama proses\n",
    "training bersama parameter lainnya. Fungsi aktivasi \\(\\phi(\\cdot)\\) digunakan\n",
    "untuk menghasilkan representasi non-linear pada output layer.\n",
    "\n",
    "Layer kustom seperti ini diimplementasikan dengan melakukan sub-class terhadap\n",
    "`tf.keras.layers.Layer`, kemudian mendefinisikan metode `build` untuk\n",
    "menginisialisasi parameter dan metode `call` untuk mendeskripsikan proses\n",
    "*forward pass* saat data dilewatkan melalui layer tersebut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc6c850-e868-4678-b7c3-9487cf52c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " mul_bias_dense (MulBiasDens  (None, 32)               192       \n",
      " e)                                                              \n",
      "                                                                 \n",
      " mul_bias_dense_1 (MulBiasDe  (None, 16)               544       \n",
      " nse)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 787\n",
      "Trainable params: 787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class MulBiasDense(layers.Layer):\n",
    "    def __init__(self, units=32, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # create weights\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True,\n",
    "            name=\"w\"\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True,\n",
    "            name=\"b\"\n",
    "        )\n",
    "        self.b_mul = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True,\n",
    "            name=\"b_mul\"\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        out = tf.matmul(inputs, self.w) + self.b + self.b_mul\n",
    "        if self.activation is not None:\n",
    "            return tf.keras.activations.get(self.activation)(out)\n",
    "        return out\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "inp_c = Input(shape=(4,))\n",
    "h_c = MulBiasDense(units=32, activation=\"relu\")(inp_c)\n",
    "h_c = MulBiasDense(units=16, activation=\"relu\")(h_c)\n",
    "out_c = Dense(3, activation=\"softmax\")(h_c)\n",
    "\n",
    "model_c = models.Model(inputs=inp_c, outputs=out_c)\n",
    "model_c.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_c.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27976ee5-9ca6-47e0-9b60-467624c6bf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8533333539962769, 0.4686679542064667)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_c = model_c.fit(\n",
    "    X.values,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=25,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "history_c.history[\"accuracy\"][-1], history_c.history[\"loss\"][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bab49-f020-4d52-8b8e-cfe7b9e7090d",
   "metadata": {},
   "source": [
    "## üöö tf.data API untuk Input Pipeline\n",
    "\n",
    "**Theory**: `tf.data` menyediakan mekanisme yang fleksibel dan efisien untuk\n",
    "membangun *input pipeline*, mulai dari membaca data dari file atau CSV,\n",
    "menerapkan transformasi seperti decoding, resizing, dan normalisasi,\n",
    "hingga melakukan pengacakan (*shuffle*) dan pembagian data ke dalam batch\n",
    "sebelum diproses oleh model.\n",
    "\n",
    "Pipeline input yang umum digunakan diawali dengan pembuatan objek\n",
    "`tf.data.Dataset` dari sumber data, seperti file atau CSV. Selanjutnya,\n",
    "fungsi `map` digunakan untuk membaca dan melakukan *preprocessing* data,\n",
    "misalnya dengan `tf.io.read_file`, `tf.image.decode_png`, dan\n",
    "`tf.image.resize`. Setelah itu, data diacak menggunakan `shuffle`,\n",
    "dibagi ke dalam batch dengan `batch`, dan dioptimalkan menggunakan\n",
    "`prefetch` agar proses input data dan komputasi model dapat berjalan\n",
    "secara paralel dan lebih efisien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4d87708-5748-49c0-90bd-01fa96c11e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "# dataset sederhana dari X, y (Iris)\n",
    "ds = tf.data.Dataset.from_tensor_slices((X.values.astype(\"float32\"), y))\n",
    "\n",
    "ds = ds.shuffle(buffer_size=150, reshuffle_each_iteration=True)\n",
    "ds = ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for batch_x, batch_y in ds.take(1):\n",
    "    print(batch_x.shape, batch_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020da6a-f53c-4c08-a048-10b125b7b84f",
   "metadata": {},
   "source": [
    "## üåâ Keras ImageDataGenerator & `tensorflow-datasets`\n",
    "\n",
    "**Theory**: Keras menyediakan beberapa utilitas untuk mempermudah pengelolaan\n",
    "data pada proses pelatihan model, khususnya untuk data citra dan dataset\n",
    "standar yang telah tersedia.\n",
    "\n",
    "`ImageDataGenerator` berfungsi sebagai generator data citra yang mendukung\n",
    "berbagai teknik augmentasi, seperti rotasi, *flip*, dan *rescaling*, serta\n",
    "menyediakan mekanisme pemuatan data langsung dari struktur folder atau\n",
    "`DataFrame`. Pendekatan ini sangat cocok digunakan untuk tahap prototyping\n",
    "cepat pada permasalahan pengolahan citra.\n",
    "\n",
    "Selain itu, paket `tensorflow-datasets (tfds)` menyediakan akses mudah ke\n",
    "berbagai dataset standar, seperti CIFAR-10, Caltech101, dan IMDb, yang dapat\n",
    "dimuat hanya dengan satu perintah `tfds.load`. Dataset yang dihasilkan sudah\n",
    "berbentuk `tf.data.Dataset` sehingga dapat langsung di-*batch* dan digunakan\n",
    "dalam pelatihan model Keras.\n",
    "\n",
    "Kedua pendekatan tersebut dapat diintegrasikan langsung dengan model Keras\n",
    "melalui fungsi `model.fit(generator_or_dataset, ...)`, tanpa memerlukan\n",
    "penulisan loop pelatihan secara manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063cd84-ded4-44ed-bc6c-5940f89f56aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
