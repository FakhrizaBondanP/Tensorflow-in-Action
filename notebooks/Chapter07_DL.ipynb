{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458aab6f-24e9-4876-806f-96d6edeca4d0",
   "metadata": {},
   "source": [
    "# üß† Teaching Machines to See Better ‚Äì Improving CNNs and Making Them Confess\n",
    "**Source: TensorFlow in Action ‚Äì Chapter 7**\n",
    "\n",
    "Chapter ini fokus ke tiga hal: mengurangi overfitting Inception v1 di Tiny ImageNet, mendesain arsitektur baru Minception (Inception‚ÄëResNet‚Äëstyle), dan menjelaskan prediksi CNN dengan Grad‚ÄëCAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e14d57-ff84-4bcf-99e7-9bb49b399ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5c380-2087-4201-bdaf-ce5236bfbc7b",
   "metadata": {},
   "source": [
    "## üìà Mengurangi Overfitting dengan Data Augmentation\n",
    "\n",
    "**Theory**: Data augmentation menambah variasi data tanpa label baru sehingga model lebih general dan kurang overfit.\n",
    "\n",
    "Augmentasi yang digunakan:\n",
    "- Rotasi acak, pergeseran horizontal/vertikal\n",
    "- Perubahan brightness, shear, zoom\n",
    "- Horizontal flip dan pengisian area kosong dengan `reflect`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a624b253-ecfd-42eb-aee2-2262d4a40320",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 4321\n",
    "batch_size = 128\n",
    "target_size = (56, 56)  # untuk Tiny ImageNet (cropped dari 64√ó64)\n",
    "\n",
    "imagegen_aug = ImageDataGenerator(\n",
    "    samplewise_center=False,       # normalisasi manual nanti\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    shear_range=5,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"reflect\",\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "imagegen = ImageDataGenerator(samplewise_center=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e90cf06-8914-410e-923a-9f89a3692a36",
   "metadata": {},
   "source": [
    "## üöö Data Pipeline: Train, Validation, Test\n",
    "\n",
    "**Theory**: Train di‚Äëaugmentasi, sedangkan validation dan test tidak di‚Äëaugmentasi agar mengukur performa pada distribusi asli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a67c14-2686-4a1a-8e83-10030a04a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "data_dir = os.path.join(\"data\", \"tiny-imagenet-200\")\n",
    "\n",
    "partial_flow = partial(\n",
    "    imagegen_aug.flow_from_directory,\n",
    "    directory=os.path.join(data_dir, \"train\"),\n",
    "    target_size=target_size,\n",
    "    classes=None,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=random_seed,\n",
    ")\n",
    "\n",
    "train_gen = partial_flow(subset=\"training\")\n",
    "valid_gen = partial_flow(subset=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b871f076-e95b-4c89-a9e6-b6b3dfe4c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_test_labels_df(ann_path):\n",
    "    df = pd.read_csv(ann_path, sep=\"\\t\", header=None)\n",
    "    df = df.iloc[:, [0, 1]].rename({0: \"filename\", 1: \"class\"}, axis=1)\n",
    "    return df\n",
    "\n",
    "test_df = get_test_labels_df(\n",
    "    os.path.join(data_dir, \"val\", \"val_annotations.txt\")\n",
    ")\n",
    "\n",
    "test_gen = imagegen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=os.path.join(data_dir, \"val\", \"images\"),\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=target_size,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea579f-2466-4959-b91c-567b607dd358",
   "metadata": {},
   "source": [
    "## üîÄ Generator Multi-output untuk Inception v1\n",
    "\n",
    "**Theory**: Inception v1 punya 1 output utama + 2 auxiliary classifier; jadi generator harus mengoutput `{\"final\": y, \"aux1\": y, \"aux2\": y}` untuk satu input batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a411a3-113b-43e7-aea5-9a032876c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(x):\n",
    "    # contoh: normalisasi sample-wise manual\n",
    "    x = x.astype(\"float32\")\n",
    "    mean = np.mean(x, axis=(1, 2, 3), keepdims=True)\n",
    "    std = np.std(x, axis=(1, 2, 3), keepdims=True) + 1e-6\n",
    "    return (x - mean) / std\n",
    "\n",
    "def datagen_augmented_inceptionv1(gen):\n",
    "    for x, y in gen:\n",
    "        x = preprocess_batch(x)\n",
    "        yield x, {\"final\": y, \"aux1\": y, \"aux2\": y}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e367fe-44b9-4f99-90f6-81c5713f8d5d",
   "metadata": {},
   "source": [
    "## ‚èπÔ∏è Early Stopping dan LR Scheduling\n",
    "\n",
    "**Theory**: Early stopping menghentikan training saat `val_loss` tidak membaik; LR scheduler menurunkan learning rate jika `val_loss` stagnan sehingga training lebih stabil dan menghindari overfitting berat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6ad72e-6ed2-471c-a946-978315168361",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_final_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_sched = ReduceLROnPlateau(\n",
    "    monitor=\"val_final_loss\",\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(\"eval/inceptionv1_improved.log\", append=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18718169-da96-4d9e-956d-968d7eb82d84",
   "metadata": {},
   "source": [
    "## üß© Minception: Inception-ResNet-style Tiny ImageNet\n",
    "\n",
    "**Theory**: Minception adalah arsitektur yang terinspirasi Inception‚ÄëResNet v2, tetapi diperkecil untuk Tiny ImageNet. Komponen utama:\n",
    "\n",
    "- **Stem**: CNN awal dengan beberapa conv paralel dan batch normalization di antara conv dan aktivasi.\n",
    "- **Inception‚ÄëResNet A/B blocks**: beberapa branch conv (1√ó1, 3√ó3, faktorisasi 5√ó5) dengan **residual connection** ke input.\n",
    "- **Reduction blocks**: menurunkan ukuran spatial sambil menaikkan depth channel.\n",
    "- Head: average pooling ‚Üí flatten ‚Üí dropout ‚Üí Dense(200, softmax).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0101a4-ee57-4ef7-8626-963f806d5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = \"glorot_uniform\"\n",
    "\n",
    "def stem(inp, activation=\"relu\", bn=True):\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(2, 2),\n",
    "                      padding=\"same\", activation=None,\n",
    "                      kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(1, 1),\n",
    "                      padding=\"same\", activation=None,\n",
    "                      kernel_initializer=init)(x)\n",
    "    if bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), strides=(1, 1),\n",
    "                      padding=\"same\", activation=None,\n",
    "                      kernel_initializer=init)(x)\n",
    "    if bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    branch1 = layers.MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    branch2 = layers.Conv2D(96, (3, 3), strides=(2, 2),\n",
    "                            padding=\"same\", activation=None,\n",
    "                            kernel_initializer=init)(x)\n",
    "    if bn:\n",
    "        branch2 = layers.BatchNormalization()(branch2)\n",
    "    branch2 = layers.Activation(activation)(branch2)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([branch1, branch2])\n",
    "\n",
    "    b1 = layers.Conv2D(64, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(x)\n",
    "    if bn:\n",
    "        b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation(activation)(b1)\n",
    "    b1 = layers.Conv2D(96, (3, 3), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b1)\n",
    "    if bn:\n",
    "        b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation(activation)(b1)\n",
    "\n",
    "    b2 = layers.Conv2D(64, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(x)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "    b2 = layers.Conv2D(64, (7, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b2)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Conv2D(64, (1, 7), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b2)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "    b2 = layers.Conv2D(96, (3, 3), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b2)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([b1, b2])\n",
    "\n",
    "    b3 = layers.MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    b4 = layers.Conv2D(192, (3, 3), strides=(2, 2),\n",
    "                       padding=\"same\", activation=None,\n",
    "                       kernel_initializer=init)(x)\n",
    "    if bn:\n",
    "        b4 = layers.BatchNormalization()(b4)\n",
    "    b4 = layers.Activation(activation)(b4)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([b3, b4])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0a1817-524f-4b05-8a39-626fe89c583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnet_block_A(inp, scale=0.1, activation=\"relu\", bn=True):\n",
    "    init_x = inp\n",
    "\n",
    "    b1 = layers.Conv2D(32, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation(activation)(b1)\n",
    "\n",
    "    b2 = layers.Conv2D(32, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "    b2 = layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b2)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "\n",
    "    b3 = layers.Conv2D(32, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        b3 = layers.BatchNormalization()(b3)\n",
    "    b3 = layers.Activation(activation)(b3)\n",
    "    b3 = layers.Conv2D(48, (3, 3), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b3)\n",
    "    if bn:\n",
    "        b3 = layers.BatchNormalization()(b3)\n",
    "    b3 = layers.Activation(activation)(b3)\n",
    "    b3 = layers.Conv2D(64, (3, 3), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b3)\n",
    "    if bn:\n",
    "        b3 = layers.BatchNormalization()(b3)\n",
    "    b3 = layers.Activation(activation)(b3)\n",
    "\n",
    "    mixed = layers.Concatenate(axis=-1)([b1, b2, b3])\n",
    "    up = layers.Conv2D(inp.shape[-1], (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(mixed)\n",
    "\n",
    "    x = layers.Lambda(lambda z: z[0] + scale * z[1])([init_x, up])\n",
    "    if bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef335acb-80e5-49cf-87f7-cd3a96cdc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block(inp, activation=\"relu\", bn=True):\n",
    "    b1 = layers.MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(inp)\n",
    "\n",
    "    b2 = layers.Conv2D(192, (3, 3), strides=(2, 2),\n",
    "                       padding=\"same\", activation=None,\n",
    "                       kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([b1, b2])\n",
    "    return x\n",
    "\n",
    "def inception_resnet_block_B(inp, scale=0.1, activation=\"relu\", bn=True):\n",
    "    init_x = inp\n",
    "\n",
    "    b1 = layers.Conv2D(128, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation(activation)(b1)\n",
    "\n",
    "    b2 = layers.Conv2D(128, (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(inp)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "    b2 = layers.Conv2D(128, (1, 7), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b2)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "    b2 = layers.Conv2D(128, (7, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(b2)\n",
    "    if bn:\n",
    "        b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation(activation)(b2)\n",
    "\n",
    "    mixed = layers.Concatenate(axis=-1)([b1, b2])\n",
    "    up = layers.Conv2D(inp.shape[-1], (1, 1), padding=\"same\",\n",
    "                       activation=None, kernel_initializer=init)(mixed)\n",
    "\n",
    "    x = layers.Lambda(lambda z: z[0] + scale * z[1])([init_x, up])\n",
    "    if bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf580000-d908-4490-8ef8-d469d4e6effb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 56, 56, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 28, 28, 32)   896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 28, 28, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 28, 28, 32)   9248        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 28, 28, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 64)   18496       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 14, 14, 96)   55392       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 14, 14, 96)  384         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 14, 14, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 14, 14, 96)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 14, 14, 160)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 14, 14, 64)   10304       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 14, 14, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 14, 14, 64)   28736       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 14, 14, 64)   10304       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 14, 14, 64)   28736       ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 14, 14, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 14, 14, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 14, 14, 96)   55392       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 14, 14, 96)   55392       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 14, 96)  384         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 14, 14, 96)  384         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 14, 14, 96)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 14, 14, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 14, 14, 192)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 7, 7, 192)    331968      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 7, 7, 192)   768         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)   0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 7, 7, 192)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 7, 7, 384)    0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 7, 7, 32)     12320       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 7, 7, 32)    128         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 7, 7, 32)     12320       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 7, 7, 48)     13872       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 7, 7, 32)    128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 7, 7, 48)    192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 7, 7, 32)     12320       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 7, 7, 32)     9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 7, 7, 64)     27712       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 7, 7, 32)    128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 7, 7, 32)    128         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 7, 7, 64)    256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 7, 7, 128)    0           ['activation_10[0][0]',          \n",
      "                                                                  'activation_12[0][0]',          \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 7, 7, 384)    49536       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 7, 7, 384)    0           ['concatenate_2[0][0]',          \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 7, 7, 384)   1536        ['lambda[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 4, 4, 192)    663744      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 4, 4, 192)   768         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 384)   0           ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 4, 4, 576)    0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 4, 4, 128)    73856       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 4, 4, 128)   512         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 4, 4, 128)    114816      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 4, 4, 128)   512         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 4, 4, 128)    73856       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 4, 4, 128)    114816      ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 4, 4, 128)   512         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 4, 4, 128)   512         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 4, 4, 256)    0           ['activation_18[0][0]',          \n",
      "                                                                  'activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 576)    148032      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 4, 4, 576)    0           ['concatenate_4[0][0]',          \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 4, 4, 576)   2304        ['lambda_1[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 4, 4, 576)    0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 4, 4, 128)    73856       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 4, 4, 128)   512         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 4, 4, 128)    114816      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 4, 4, 128)   512         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 4, 128)    73856       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 128)    114816      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 4, 4, 128)   512         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 4, 4, 128)   512         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 4, 4, 256)    0           ['activation_23[0][0]',          \n",
      "                                                                  'activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 4, 4, 576)    148032      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 4, 4, 576)    0           ['activation_22[0][0]',          \n",
      "                                                                  'conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 4, 4, 576)   2304        ['lambda_2[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 4, 4, 576)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 576)         0           ['activation_27[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 576)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 200)          115400      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,587,512\n",
      "Trainable params: 2,579,800\n",
      "Non-trainable params: 7,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 200\n",
    "\n",
    "inp = layers.Input(shape=(56, 56, 3))\n",
    "x = stem(inp)\n",
    "\n",
    "x = inception_resnet_block_A(x)\n",
    "x = reduction_block(x)\n",
    "x = inception_resnet_block_B(x)\n",
    "x = inception_resnet_block_B(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "minception = models.Model(inputs=inp, outputs=out)\n",
    "minception.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412cbb1a-ccf6-4c60-9c7f-8700f367b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(x):\n",
    "    x = x.astype(\"float32\")\n",
    "    mean = np.mean(x, axis=(1, 2, 3), keepdims=True)\n",
    "    std = np.std(x, axis=(1, 2, 3), keepdims=True) + 1e-6\n",
    "    return (x - mean) / std\n",
    "\n",
    "def wrap_gen(gen):\n",
    "    while True:\n",
    "        x, y = next(gen)\n",
    "        yield preprocess_batch(x), y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c9ccb-e68a-4ff5-849a-c048a9239c7d",
   "metadata": {},
   "source": [
    "## üîÑ Transfer Learning dengan Inception-ResNet v2\n",
    "\n",
    "**Theory**: Pretrained Inception‚ÄëResNet v2 di ImageNet digunakan sebagai feature extractor; head diganti dengan Dense(200) dan beberapa layer atas difine‚Äëtune untuk Tiny ImageNet, menghasilkan ~79% test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06879073-d57b-4e36-b5ff-98fffe1a1bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219055592/219055592 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "irv2_model = models.Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "irv2_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f5da2-924d-44d6-b7fd-b484eb18a136",
   "metadata": {},
   "source": [
    "## üîç Grad-CAM: Membuat CNN ‚ÄúNgaku‚Äù\n",
    "\n",
    "**Theory**: Grad‚ÄëCAM memproyeksikan gradien skor kelas ke feature map layer conv terakhir untuk menghasilkan heatmap lokasi yang paling berkontribusi pada prediksi.\n",
    "\n",
    "Formula inti:\n",
    "- Hitung gradien skor kelas \\(y^c\\) terhadap feature map \\(A^k\\).\n",
    "- Dapatkan bobot saluran:\n",
    "  $$\n",
    "  \\alpha_k^c = \\frac{1}{Z} \\sum_i \\sum_j \\frac{\\partial y^c}{\\partial A^k_{ij}}\n",
    "  $$\n",
    "- Peta Grad‚ÄëCAM:\n",
    "  $$\n",
    "  L_{\\text{Grad-CAM}}^c = \\text{ReLU}\\Big(\\sum_k \\alpha_k^c A^k\\Big)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5407c2a1-3865-4683-a0c4-c522dd3236b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap) + 1e-8\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea8cb7-2247-49e1-9461-f64c40a65e01",
   "metadata": {},
   "source": [
    "## ‚úÖ Ringkasan Chapter 7\n",
    "\n",
    "**Theory**: Chapter ini menunjukkan bagaimana mengurangi overfitting CNN dengan augmentasi, dropout, dan early stopping, lalu mendesain Minception dan memanfaatkan transfer learning untuk meningkatkan akurasi jauh lebih tinggi di Tiny ImageNet.\n",
    "\n",
    "Grad‚ÄëCAM memberikan cara visual untuk memverifikasi bahwa model fokus pada objek yang relevan, sehingga membantu debugging dan membangun kepercayaan sebelum deployment di dunia nyata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c845e-70b3-4076-9b45-b521a926a06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
