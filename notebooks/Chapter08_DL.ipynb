{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BAB 8: Image Segmentation (Segmentasi Gambar)\n",
        "\n",
        "## Ringkasan Lengkap\n",
        "\n",
        "### Pendahuluan\n",
        "\n",
        "Bab ini membahas tentang **image segmentation** (segmentasi gambar), yaitu tugas computer vision yang lebih kompleks dibandingkan klasifikasi gambar. Berbeda dengan klasifikasi yang hanya menentukan apakah objek ada dalam gambar, segmentasi gambar mengenali multiple objek sekaligus dan menentukan **lokasi** mereka dalam gambar.\n",
        "\n",
        "### Konsep Utama\n",
        "\n",
        "#### 1. Jenis-Jenis Segmentasi\n",
        "\n",
        "Ada dua kategori utama dalam image segmentation:\n",
        "\n",
        "- **Semantic Segmentation**: Algoritma hanya mengidentifikasi kategori objek yang berbeda. Jika ada beberapa orang dalam gambar, semua pixel yang bersesuaian akan ditandai dengan kelas yang sama.\n",
        "\n",
        "- **Instance Segmentation**: Algoritma mengidentifikasi setiap objek secara terpisah. Jika ada beberapa orang, pixel untuk setiap orang direpresentasikan dengan kelas unik. Instance segmentation dianggap lebih sulit dari semantic segmentation.\n",
        "\n",
        "#### 2. Dataset: PASCAL VOC 2012\n",
        "\n",
        "Bab ini menggunakan dataset PASCAL VOC 2012 yang berisi:\n",
        "- 22 kelas objek berbeda (termasuk background)\n",
        "- Gambar input standar RGB\n",
        "- Gambar target yang setiap pixelnya memiliki warna dari palette yang telah ditentukan\n",
        "- Objek seperti: aeroplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, tv/monitor\n",
        "\n",
        "#### 3. Karakteristik Data\n",
        "\n",
        "Data segmentasi berbeda dari klasifikasi:\n",
        "- **Input**: Gambar RGB standar\n",
        "- **Target**: Gambar di mana setiap pixel memiliki warna dari palette warna yang telah ditentukan\n",
        "- Target disimpan sebagai **palettized images** untuk efisiensi memori\n",
        "- White pixels merepresentasikan batas objek atau objek tidak dikenal\n",
        "\n",
        "### Pipeline Data dengan TensorFlow\n",
        "\n",
        "#### Komponen Pipeline tf.data\n",
        "\n",
        "Pipeline data yang dibangun melakukan:\n",
        "\n",
        "1. **Mendapatkan filenames** untuk subset tertentu (training, validation, testing)\n",
        "2. **Membaca gambar** dari disk\n",
        "3. **Preprocessing**: normalisasi, resize, cropping\n",
        "4. **Augmentasi data** (hanya untuk training):\n",
        "   - Random horizontal flipping\n",
        "   - Random hue adjustment (±10%)\n",
        "   - Random brightness adjustment (±10%)\n",
        "   - Random contrast adjustment (±20%)\n",
        "5. **Batching** data dalam batch kecil\n",
        "6. **Optimasi** menggunakan caching dan prefetching\n",
        "\n",
        "#### Teknik Optimasi Pipeline\n",
        "\n",
        "- **Caching**: Menyimpan data di memory setelah loading pertama kali\n",
        "- **Prefetching**: Menggunakan background threads untuk load data sambil model training\n",
        "\n",
        "### Arsitektur Model: DeepLab v3\n",
        "\n",
        "#### Komponen Utama\n",
        "\n",
        "DeepLab v3 terdiri dari beberapa komponen:\n",
        "\n",
        "1. **Backbone: ResNet-50 (Pretrained)**\n",
        "   - Diunduh dari ImageNet\n",
        "   - Digunakan hingga conv4 block\n",
        "   - Conv5 block dimodifikasi dengan atrous convolution\n",
        "\n",
        "2. **Atrous Convolution (Dilated Convolution)**\n",
        "   - Convolution dengan \"holes\" (lubang) di antara parameter\n",
        "   - Dikontrol oleh parameter **dilation rate**\n",
        "   - Meningkatkan receptive field tanpa menambah parameter\n",
        "   - Membantu mengatasi masalah output yang mengecil akibat stride/pooling\n",
        "\n",
        "3. **Atrous Spatial Pyramid Pooling (ASPP)**\n",
        "   - Modul aggregasi pyramidal yang mengumpulkan informasi multi-scale\n",
        "   - Komponen:\n",
        "     - 1×1 convolution (256 filters)\n",
        "     - 3×3 convolution dengan dilation rate=6 (256 filters)\n",
        "     - 3×3 convolution dengan dilation rate=12 (256 filters)\n",
        "     - 3×3 convolution dengan dilation rate=18 (256 filters)\n",
        "     - Global average pooling → 1×1 conv → bilinear upsampling\n",
        "   - Semua output dikoncatenasi\n",
        "\n",
        "4. **Bilinear Upsampling**\n",
        "   - Memperbesar output ke ukuran yang diinginkan\n",
        "   - Menggunakan interpolasi bilinear\n",
        "\n",
        "### Loss Functions dan Metrics\n",
        "\n",
        "#### Loss Functions\n",
        "\n",
        "1. **Weighted Categorical Cross-Entropy Loss**\n",
        "   - Mengatasi class imbalance dengan memberikan weight berbeda per kelas\n",
        "   - Sparse version digunakan (tidak perlu one-hot encoding)\n",
        "   - Computed from logits untuk stabilitas gradient\n",
        "\n",
        "2. **Dice Loss**\n",
        "   - Fokus pada memaksimalkan intersection antara prediksi dan target\n",
        "   - Formula: \\( 1 - \\frac{2 \\times \\text{Intersection}}{\\text{Union} + \\text{Intersection}} \\)\n",
        "   - Intersection: element-wise multiplication\n",
        "   - Union: element-wise addition\n",
        "\n",
        "3. **Combined Loss**: CE + Dice Loss\n",
        "\n",
        "#### Evaluation Metrics\n",
        "\n",
        "1. **Pixel Accuracy**\n",
        "   - Mengukur persentase pixel yang diprediksi dengan benar\n",
        "   - Formula: \\( \\frac{\\text{Correct Pixels}}{\\text{Total Pixels}} \\)\n",
        "\n",
        "2. **Mean Accuracy**\n",
        "   - Average dari per-class accuracy\n",
        "   - Lebih baik untuk menangani class imbalance\n",
        "\n",
        "3. **Mean IoU (Intersection over Union)**\n",
        "   - Metric paling populer untuk segmentasi\n",
        "   - Formula: \\( \\frac{\\text{True Positives}}{\\text{True Positives + False Positives + False Negatives}} \\)\n",
        "\n",
        "### Training dan Evaluasi\n",
        "\n",
        "#### Hyperparameters\n",
        "\n",
        "- **Input size**: 384 × 384\n",
        "- **Batch size**: Sesuai kebutuhan memory\n",
        "- **Optimizer**: Adam atau SGD\n",
        "- **Learning rate**: Dengan learning rate scheduling\n",
        "- **Data augmentation**: Enabled untuk training, disabled untuk validation/test\n",
        "\n",
        "#### Hasil\n",
        "\n",
        "Model DeepLab v3 mencapai akurasi sekitar **62% mean IoU** pada Pascal VOC 2012 dataset, menunjukkan performa yang sangat baik.\n",
        "\n",
        "### Kesimpulan Penting\n",
        "\n",
        "1. **Segmentation vs Classification**: Segmentation adalah dense prediction task (setiap pixel diprediksi), sedangkan classification adalah sparse prediction (satu label per gambar).\n",
        "\n",
        "2. **Transfer Learning**: Pretrained models (ResNet-50 dari ImageNet) sangat membantu sebagai backbone.\n",
        "\n",
        "3. **Multi-scale Information**: ASPP module penting untuk menggabungkan informasi dari berbagai scale (fine-grained dan coarse).\n",
        "\n",
        "4. **Data Pipeline**: tf.data API powerful untuk membuat pipeline yang efisien dan scalable.\n",
        "\n",
        "5. **Custom Components**: TensorFlow/Keras memungkinkan implementasi custom loss functions dan metrics dengan mudah.\n",
        "\n",
        "---\n",
        "\n",
        "## Program-Program Penting\n",
        "\n",
        "### 1. Download dan Extract Data\n",
        "\n",
        "```python\n",
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "# Retrieve the data\n",
        "if not os.path.exists(os.path.join('data','VOCtrainval_11-May-2012.tar')):\n",
        "    url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
        "    \n",
        "    # Get the file from web\n",
        "    r = requests.get(url)      \n",
        "    if not os.path.exists('data'):\n",
        "        os.mkdir('data')\n",
        "    \n",
        "    # Write to a file\n",
        "    with open(os.path.join('data','VOCtrainval_11-May-2012.tar'), 'wb') as f:\n",
        "        f.write(r.content)               \n",
        "else:\n",
        "    print(\"The tar file already exists.\")\n",
        "    \n",
        "if not os.path.exists(os.path.join('data', 'VOCtrainval_11-May-2012')):    \n",
        "    with tarfile.open(os.path.join('data','VOCtrainval_11-May-2012.tar'), 'r') as tar:\n",
        "        tar.extractall('data')\n",
        "else:\n",
        "    print(\"The extracted data already exists\")\n",
        "```\n",
        "\n",
        "### 2. Rekonstruksi Gambar dari Palettized Image\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngImageFile\n",
        "\n",
        "def rgb_image_from_palette(image):\n",
        "    \"\"\" This function restores the RGB values form a palletted PNG image \"\"\"\n",
        "    palette = image.get_palette()       \n",
        "    palette = np.array(palette).reshape(-1,3)    \n",
        "    \n",
        "    if isinstance(image, PngImageFile):\n",
        "        h, w = image.height, image.width     \n",
        "        # Squash height and width dimensions (makes slicing easier)\n",
        "        image = np.array(image).reshape(-1)   \n",
        "    elif isinstance(image, np.ndarray):    \n",
        "        h, w = image.shape[0], image.shape[1]\n",
        "        image = image.reshape(-1)\n",
        "        \n",
        "    rgb_image = np.zeros(shape=(image.shape[0],3))                 \n",
        "    rgb_image[(image != 0),:] = palette[image[(image != 0)], :]   \n",
        "    rgb_image = rgb_image.reshape(h, w, 3)   \n",
        "    \n",
        "    return rgb_image\n",
        "```\n",
        "\n",
        "### 3. Generator untuk Mendapatkan Filenames\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def get_subset_filenames(orig_dir, seg_dir, subset_dir, subset, random_seed=42):\n",
        "    \"\"\" Get the filenames for a given subset (train/valid/test)\"\"\"\n",
        "    if subset.startswith('train'):\n",
        "        ser = pd.read_csv(                         \n",
        "            os.path.join(subset_dir, \"train.txt\"),\n",
        "            index_col=None, header=None, squeeze=True\n",
        "        ).tolist()\n",
        "    elif subset.startswith('val') or subset.startswith('test'):\n",
        "        random.seed(random_seed)   \n",
        "        ser = pd.read_csv(                   \n",
        "            os.path.join(subset_dir, \"val.txt\"),\n",
        "            index_col=None, header=None, squeeze=True\n",
        "        ).tolist()\n",
        "\n",
        "        random.shuffle(ser)   \n",
        "        if subset.startswith('val'):\n",
        "            ser = ser[:len(ser)//2]     \n",
        "        else:\n",
        "            ser = ser[len(ser)//2:]       \n",
        "    else:\n",
        "        raise NotImplementedError(\"Subset={} is not recognized\".format(subset))\n",
        "    \n",
        "    orig_filenames = [os.path.join(orig_dir,f+'.jpg') for f in ser]   \n",
        "    seg_filenames = [os.path.join(seg_dir, f+'.png') for f in ser]  \n",
        "    \n",
        "    for o, s in zip(orig_filenames, seg_filenames):\n",
        "        yield o, s\n",
        "```\n",
        "\n",
        "### 4. Random Crop atau Resize\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "def randomly_crop_or_resize(x, y, input_size, resize_to_before_crop, augmentation=False):\n",
        "    \"\"\" Randomly crops or resizes the images \"\"\"\n",
        "    \n",
        "    def rand_crop(x, y):\n",
        "        \"\"\" Randomly crop images after enlarging them \"\"\"\n",
        "        x = tf.image.resize(x, resize_to_before_crop, method='bilinear')   \n",
        "        y = tf.cast(                                     \n",
        "                tf.image.resize(\n",
        "                    tf.transpose(y,[1,2,0]),           \n",
        "                    resize_to_before_crop, method='nearest'\n",
        "                ),\n",
        "                'float32'\n",
        "            )          \n",
        "        offset_h = tf.random.uniform(\n",
        "            [], 0, x.shape[0]-input_size[0], dtype='int32'\n",
        "        )   \n",
        "        offset_w = tf.random.uniform(\n",
        "            [], 0, x.shape[1]-input_size[1], dtype='int32'\n",
        "        )   \n",
        "        x = tf.image.crop_to_bounding_box(\n",
        "            image=x,\n",
        "            offset_height=offset_h, offset_width=offset_w,\n",
        "            target_height=input_size[0], target_width=input_size[1]  \n",
        "        )\n",
        "        y = tf.image.crop_to_bounding_box(\n",
        "            image=y,\n",
        "            offset_height=offset_h, offset_width=offset_w,\n",
        "            target_height=input_size[0], target_width=input_size[1]  \n",
        "        )\n",
        "        return x, y\n",
        "    \n",
        "    def resize(x, y):\n",
        "        \"\"\" Resize images to a desired size \"\"\"\n",
        "        x = tf.image.resize(x, input_size, method='bilinear')   \n",
        "        y = tf.cast(\n",
        "                tf.image.resize(\n",
        "                    tf.transpose(y,[1,2,0]),                                        \n",
        "                    input_size, method='nearest'                \n",
        "                ),\n",
        "                'float32'\n",
        "            )          \n",
        "        return x, y\n",
        "    \n",
        "    rand = tf.random.uniform([], 0.0, 1.0)    \n",
        "    \n",
        "    if augmentation and \\\n",
        "        (input_size[0] < resize_to_before_crop[0] or \\\n",
        "         input_size[1] < resize_to_before_crop[1]):\n",
        "        x, y = tf.cond(\n",
        "                rand < 0.5,                \n",
        "                lambda: rand_crop(x, y),\n",
        "                lambda: resize(x, y)\n",
        "                )\n",
        "    else:\n",
        "        x, y = resize(x, y)    \n",
        "    \n",
        "    return x, y\n",
        "```\n",
        "\n",
        "### 5. Augmentasi Data\n",
        "\n",
        "```python\n",
        "def randomly_flip_horizontal(x, y):\n",
        "    \"\"\" Randomly flip images horizontally. \"\"\"\n",
        "    rand = tf.random.uniform([], 0.0, 1.0)   \n",
        "    \n",
        "    def flip(x, y):\n",
        "        return tf.image.flip_left_right(x), tf.image.flip_left_right(y)   \n",
        "    \n",
        "    x, y = tf.cond(rand < 0.5, lambda: flip(x, y), lambda: (x, y))     \n",
        "    return x, y\n",
        "```\n",
        "\n",
        "### 6. Pipeline tf.data Lengkap\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "\n",
        "def load_image_func(image):\n",
        "    \"\"\" Load the image given a filename \"\"\"\n",
        "    img = np.array(Image.open(image))        \n",
        "    return img\n",
        "\n",
        "def fix_shape(x, y, size):\n",
        "    \"\"\" Set the shape of the input/target tensors \"\"\"\n",
        "    x.set_shape((size[0], size[1], 3))\n",
        "    y.set_shape((size[0], size[1], 1))\n",
        "    return x, y\n",
        "\n",
        "def get_subset_tf_dataset(\n",
        "    subset_filename_gen_func, batch_size, epochs,\n",
        "    input_size=(256, 256), output_size=None, resize_to_before_crop=None,\n",
        "    augmentation=False, shuffle=False\n",
        "):\n",
        "    \n",
        "    if augmentation and not resize_to_before_crop:\n",
        "        raise RuntimeError(\n",
        "            \"You must define resize_to_before_crop when augmentation is enabled.\"\n",
        "        )\n",
        "        \n",
        "    # Create dataset from generator\n",
        "    filename_ds = tf.data.Dataset.from_generator(\n",
        "        subset_filename_gen_func, output_types=(tf.string, tf.string)\n",
        "    )\n",
        "    \n",
        "    # Load images\n",
        "    image_ds = filename_ds.map(lambda x,y: (\n",
        "        tf.image.decode_jpeg(tf.io.read_file(x)),\n",
        "        tf.numpy_function(load_image_func, [y], [tf.uint8])\n",
        "    )).cache()\n",
        "    \n",
        "    # Normalize\n",
        "    image_ds = image_ds.map(lambda x, y: (tf.cast(x, 'float32')/255.0, y))\n",
        "    \n",
        "    # Random crop or resize\n",
        "    image_ds = image_ds.map(lambda x,y: randomly_crop_or_resize(\n",
        "        x, y, input_size, resize_to_before_crop, augmentation\n",
        "    ))\n",
        "    \n",
        "    # Fix shape\n",
        "    image_ds = image_ds.map(lambda x,y: fix_shape(x, y, target_size=input_size))\n",
        "    \n",
        "    # Augmentation\n",
        "    if augmentation:    \n",
        "        image_ds = image_ds.map(lambda x, y: randomly_flip_horizontal(x,y))\n",
        "        image_ds = image_ds.map(lambda x, y: (tf.image.random_hue(x, 0.1), y))\n",
        "        image_ds = image_ds.map(lambda x, y: (tf.image.random_brightness(x, 0.1), y))\n",
        "        image_ds = image_ds.map(lambda x, y: (tf.image.random_contrast(x, 0.8, 1.2), y))\n",
        "    \n",
        "    # Resize output if needed\n",
        "    if output_size:\n",
        "        image_ds = image_ds.map(\n",
        "            lambda x, y: (x, tf.image.resize(y, output_size, method='nearest'))\n",
        "        )\n",
        "    \n",
        "    # Shuffle\n",
        "    if shuffle:\n",
        "        image_ds = image_ds.shuffle(buffer_size=batch_size*5)\n",
        "    \n",
        "    # Batch and repeat\n",
        "    image_ds = image_ds.batch(batch_size).repeat(epochs)\n",
        "    \n",
        "    # Prefetch\n",
        "    image_ds = image_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    # Squeeze target\n",
        "    image_ds = image_ds.map(lambda x, y: (x, tf.squeeze(y)))\n",
        "    \n",
        "    return image_ds\n",
        "```\n",
        "\n",
        "### 7. Membuat Instances Pipeline Train/Val/Test\n",
        "\n",
        "```python\n",
        "# Define directories\n",
        "orig_dir = os.path.join(\n",
        "    'data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'JPEGImages'\n",
        ")\n",
        "seg_dir = os.path.join(\n",
        "    'data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'SegmentationClass'\n",
        ")\n",
        "subset_dir = os.path.join(\n",
        "    'data', 'VOCtrainval_11-May-2012', 'VOCdevkit', 'VOC2012', 'ImageSets', 'Segmentation'\n",
        ")\n",
        "\n",
        "# Create partial functions\n",
        "partial_subset_fn = partial(\n",
        "    get_subset_filenames, orig_dir=orig_dir, seg_dir=seg_dir, subset_dir=subset_dir\n",
        ")\n",
        "\n",
        "train_subset_fn = partial(partial_subset_fn, subset='train')\n",
        "val_subset_fn = partial(partial_subset_fn, subset='val')\n",
        "test_subset_fn = partial(partial_subset_fn, subset='test')\n",
        "\n",
        "# Parameters\n",
        "input_size = (384, 384)\n",
        "batch_size = 8\n",
        "epochs = 50\n",
        "\n",
        "# Create pipelines\n",
        "tr_image_ds = get_subset_tf_dataset(\n",
        "    train_subset_fn, batch_size, epochs,\n",
        "    input_size=input_size, resize_to_before_crop=(444,444),\n",
        "    augmentation=True, shuffle=True\n",
        ")\n",
        "\n",
        "val_image_ds = get_subset_tf_dataset(\n",
        "    val_subset_fn, batch_size, epochs,\n",
        "    input_size=input_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_image_ds = get_subset_tf_dataset(\n",
        "    test_subset_fn, batch_size, 1,\n",
        "    input_size=input_size,\n",
        "    shuffle=False\n",
        ")\n",
        "```\n",
        "\n",
        "### 8. Level 3 Block (Atrous Convolution Block)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def block_level3(inp, filters, kernel_size, rate, block_id, convlayer_id, activation=True):\n",
        "    \"\"\" A single convolution layer with atrous convolution and batch normalization \"\"\"\n",
        "    \n",
        "    conv5_block_conv_out = layers.Conv2D(\n",
        "        filters, kernel_size, dilation_rate=rate, padding='same',\n",
        "        name='conv5_block{}_{}_conv'.format(block_id, convlayer_id)\n",
        "    )(inp)\n",
        "    \n",
        "    conv5_block_bn_out = layers.BatchNormalization(\n",
        "        name='conv5_block{}_{}_bn'.format(block_id, convlayer_id)\n",
        "    )(conv5_block_conv_out)\n",
        "    \n",
        "    if activation:\n",
        "        conv5_block_relu_out = layers.Activation(\n",
        "            'relu', name='conv5_block{}_{}_relu'.format(block_id, convlayer_id)\n",
        "        )(conv5_block_bn_out)\n",
        "        return conv5_block_relu_out\n",
        "    else:\n",
        "        return conv5_block_bn_out\n",
        "```\n",
        "\n",
        "### 9. Level 2 Block\n",
        "\n",
        "```python\n",
        "def block_level2(inp, rate, block_id):\n",
        "    \"\"\" A level 2 resnet block that consists of three level 3 blocks \"\"\"\n",
        "    block_1_out = block_level3(inp, 512, (1,1), rate, block_id, 1)\n",
        "    block_2_out = block_level3(block_1_out, 512, (3,3), rate, block_id, 2)\n",
        "    block_3_out = block_level3(\n",
        "        block_2_out, 2048, (1,1), rate, block_id, 3, activation=False\n",
        "    )\n",
        "    return block_3_out\n",
        "```\n",
        "\n",
        "### 10. ResNet Block dengan Atrous Convolution\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Add, Activation\n",
        "\n",
        "def resnet_block(inp, rate):\n",
        "    \"\"\" Redefining a resnet block with atrous convolution \"\"\"\n",
        "    \n",
        "    # Block 0 - for residual connection\n",
        "    block0_out = block_level3(\n",
        "        inp, 2048, (1,1), 1, block_id=1, convlayer_id=0, activation=False\n",
        "    )\n",
        "    \n",
        "    # Block 1\n",
        "    block1_out = block_level2(inp, 2, block_id=1)\n",
        "    block1_add = Add(name='conv5_block{}_add'.format(1))([block0_out, block1_out])\n",
        "    block1_relu = Activation('relu', name='conv5_block{}_relu'.format(1))(block1_add)\n",
        "    \n",
        "    # Block 2\n",
        "    block2_out = block_level2(block1_relu, 2, block_id=2)\n",
        "    block2_add = Add(name='conv5_block{}_add'.format(2))([block1_add, block2_out])\n",
        "    block2_relu = Activation('relu', name='conv5_block{}_relu'.format(2))(block2_add)\n",
        "    \n",
        "    # Block 3\n",
        "    block3_out = block_level2(block2_relu, 2, block_id=3)\n",
        "    block3_add = Add(name='conv5_block{}_add'.format(3))([block2_add, block3_out])\n",
        "    block3_relu = Activation('relu', name='conv5_block{}_relu'.format(3))(block3_add)\n",
        "    \n",
        "    return block3_relu\n",
        "```\n",
        "\n",
        "### 11. ASPP Module (Atrous Spatial Pyramid Pooling)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Lambda, UpSampling2D, Concatenate\n",
        "\n",
        "def atrous_spatial_pyramid_pooling(inp):\n",
        "    \"\"\" Defining the ASPP (Atrous spatial pyramid pooling) module \"\"\"\n",
        "    \n",
        "    # Part A: 1x1 and atrous convolutions\n",
        "    outa_1_conv = block_level3(inp, 256, (1,1), 1, '_aspp_a', 1, activation=True)\n",
        "    outa_2_conv = block_level3(inp, 256, (3,3), 6, '_aspp_a', 2, activation=True)\n",
        "    outa_3_conv = block_level3(inp, 256, (3,3), 12, '_aspp_a', 3, activation=True)\n",
        "    outa_4_conv = block_level3(inp, 256, (3,3), 18, '_aspp_a', 4, activation=True)\n",
        "    \n",
        "    # Part B: global pooling\n",
        "    outb_1_avg = Lambda(\n",
        "        lambda x: K.mean(x, axis=[1,2], keepdims=True)\n",
        "    )(inp)\n",
        "    \n",
        "    outb_1_conv = block_level3(\n",
        "        outb_1_avg, 256, (1,1), 1, '_aspp_b', 1, activation=True\n",
        "    )\n",
        "    \n",
        "    outb_1_up = UpSampling2D((24,24), interpolation='bilinear')(outb_1_conv)\n",
        "    \n",
        "    # Concatenate all outputs\n",
        "    out_aspp = Concatenate()([outa_1_conv, outa_2_conv, outa_3_conv, outa_4_conv, outb_1_up])\n",
        "    \n",
        "    return out_aspp\n",
        "```\n",
        "\n",
        "### 12. Model DeepLab v3 Lengkap\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_deeplabv3(input_size=(384, 384), num_classes=21):\n",
        "    \"\"\" Build complete DeepLab v3 model \"\"\"\n",
        "    \n",
        "    # Input layer\n",
        "    inp = layers.Input(shape=input_size+(3,))\n",
        "    \n",
        "    # Load pretrained ResNet50\n",
        "    resnet50 = tf.keras.applications.ResNet50(\n",
        "        include_top=False, input_tensor=inp, pooling=None\n",
        "    )\n",
        "    \n",
        "    # Get output up to conv4 block\n",
        "    for layer in resnet50.layers:\n",
        "        if layer.name == \"conv5_block1_1_conv\":\n",
        "            break\n",
        "        out = layer.output\n",
        "    \n",
        "    resnet50_upto_conv4 = models.Model(resnet50.input, out)\n",
        "    \n",
        "    # Add modified conv5 block with atrous convolution\n",
        "    resnet_block4_out = resnet_block(resnet50_upto_conv4.output, 2)\n",
        "    \n",
        "    # Add ASPP module\n",
        "    out_aspp = atrous_spatial_pyramid_pooling(resnet_block4_out)\n",
        "    \n",
        "    # Final convolution\n",
        "    out = layers.Conv2D(num_classes, (1,1), padding='same')(out_aspp)\n",
        "    \n",
        "    # Bilinear upsampling to original size\n",
        "    final_out = layers.UpSampling2D((16,16), interpolation='bilinear')(out)\n",
        "    \n",
        "    # Create model\n",
        "    deeplabv3 = models.Model(resnet50_upto_conv4.input, final_out)\n",
        "    \n",
        "    return deeplabv3, resnet50\n",
        "\n",
        "# Build model\n",
        "target_size = (384, 384)\n",
        "num_classes = 21\n",
        "deeplabv3, resnet50 = build_deeplabv3(target_size, num_classes)\n",
        "```\n",
        "\n",
        "### 13. Weighted Cross-Entropy Loss\n",
        "\n",
        "```python\n",
        "def get_label_weights(y_true, y_pred):\n",
        "    \"\"\" Get weights for each class based on frequency \"\"\"\n",
        "    \n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    \n",
        "    # Count occurrences of each class\n",
        "    class_counts = tf.math.bincount(\n",
        "        tf.cast(y_true, 'int32'),\n",
        "        minlength=num_classes,\n",
        "        maxlength=num_classes\n",
        "    )\n",
        "    \n",
        "    # Calculate weights (inverse frequency)\n",
        "    total_count = tf.reduce_sum(class_counts)\n",
        "    class_weights = total_count / (tf.cast(class_counts, 'float32') + 1.0)\n",
        "    \n",
        "    # Normalize weights\n",
        "    class_weights = class_weights / tf.reduce_sum(class_weights) * num_classes\n",
        "    \n",
        "    # Get weight for each pixel\n",
        "    pixel_weights = tf.gather(class_weights, tf.cast(y_true, 'int32'))\n",
        "    \n",
        "    return pixel_weights\n",
        "\n",
        "def ce_weighted_from_logits(num_classes):\n",
        "    \"\"\" Weighted cross-entropy loss from logits \"\"\"\n",
        "    \n",
        "    def loss_fn(y_true, y_pred):\n",
        "        # Cast and set shape\n",
        "        y_true = tf.cast(y_true, 'int32')\n",
        "        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "        \n",
        "        # Create valid mask\n",
        "        valid_mask = tf.reshape((y_true <= num_classes - 1), [-1])\n",
        "        \n",
        "        # Get weights\n",
        "        weights = get_label_weights(y_true, y_pred)\n",
        "        \n",
        "        # Unwrap tensors\n",
        "        y_true_unwrap = tf.reshape(y_true, [-1])\n",
        "        y_pred_unwrap = tf.reshape(y_pred, [-1, num_classes])\n",
        "        \n",
        "        # Mask valid pixels\n",
        "        y_true_unwrap = tf.boolean_mask(y_true_unwrap, valid_mask)\n",
        "        y_pred_unwrap = tf.boolean_mask(y_pred_unwrap, valid_mask)\n",
        "        weights = tf.boolean_mask(weights, valid_mask)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            labels=y_true_unwrap,\n",
        "            logits=y_pred_unwrap\n",
        "        )\n",
        "        \n",
        "        # Weight the loss\n",
        "        weighted_loss = loss * weights\n",
        "        \n",
        "        return tf.reduce_mean(weighted_loss)\n",
        "    \n",
        "    return loss_fn\n",
        "```\n",
        "\n",
        "### 14. Dice Loss\n",
        "\n",
        "```python\n",
        "def dice_loss_from_logits(num_classes):\n",
        "    \"\"\" Defining the dice loss: 1 - [(2*i + 1)/(u + i)] \"\"\"\n",
        "    \n",
        "    def loss_fn(y_true, y_pred):\n",
        "        smooth = 1.0\n",
        "        \n",
        "        # Cast and set shape\n",
        "        y_true = tf.cast(y_true, 'int32')\n",
        "        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "        \n",
        "        # Get pixel weights\n",
        "        y_weights = tf.reshape(get_label_weights(y_true, y_pred), [-1, 1])\n",
        "        \n",
        "        # Apply softmax to logits\n",
        "        y_pred = tf.nn.softmax(y_pred)\n",
        "        \n",
        "        # Unwrap and one-hot encode\n",
        "        y_true_unwrap = tf.reshape(y_true, [-1])\n",
        "        y_true_unwrap = tf.cast(\n",
        "            tf.one_hot(tf.cast(y_true_unwrap, 'int32'), num_classes),\n",
        "            'float32'\n",
        "        )\n",
        "        y_pred_unwrap = tf.reshape(y_pred, [-1, num_classes])\n",
        "        \n",
        "        # Compute intersection and union\n",
        "        intersection = tf.reduce_sum(y_true_unwrap * y_pred_unwrap * y_weights)\n",
        "        union = tf.reduce_sum((y_true_unwrap + y_pred_unwrap) * y_weights)\n",
        "        \n",
        "        # Compute dice coefficient\n",
        "        score = (2.0 * intersection + smooth) / (union + smooth)\n",
        "        \n",
        "        # Compute dice loss\n",
        "        loss = 1.0 - score\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    return loss_fn\n",
        "```\n",
        "\n",
        "### 15. Combined Loss Function\n",
        "\n",
        "```python\n",
        "def ce_dice_loss_from_logits(num_classes):\n",
        "    \"\"\" Combined cross-entropy and dice loss \"\"\"\n",
        "    \n",
        "    ce_loss_fn = ce_weighted_from_logits(num_classes)\n",
        "    dice_loss_fn = dice_loss_from_logits(num_classes)\n",
        "    \n",
        "    def loss_fn(y_true, y_pred):\n",
        "        ce_loss = ce_loss_fn(y_true, y_pred)\n",
        "        dice_loss = dice_loss_fn(y_true, y_pred)\n",
        "        \n",
        "        # Combine losses (equal weight)\n",
        "        total_loss = ce_loss + dice_loss\n",
        "        \n",
        "        return total_loss\n",
        "    \n",
        "    return loss_fn\n",
        "```\n",
        "\n",
        "### 16. Pixel Accuracy Metric\n",
        "\n",
        "```python\n",
        "class PixelAccuracyMetric(tf.keras.metrics.Mean):\n",
        "    \"\"\" Pixel accuracy metric \"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes, name='pixel_accuracy', **kwargs):\n",
        "        super(PixelAccuracyMetric, self).__init__(name=name, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "    \n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Set shape\n",
        "        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "        \n",
        "        # Flatten\n",
        "        y_true = tf.reshape(y_true, [-1])\n",
        "        y_pred = tf.reshape(tf.argmax(y_pred, axis=-1), [-1])\n",
        "        \n",
        "        # Create valid mask\n",
        "        valid_mask = tf.reshape((y_true <= self.num_classes - 1), [-1])\n",
        "        \n",
        "        # Mask valid pixels\n",
        "        y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "        y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "        \n",
        "        # Compute accuracy\n",
        "        correct = tf.cast(tf.equal(y_true, y_pred), 'float32')\n",
        "        accuracy = tf.reduce_mean(correct)\n",
        "        \n",
        "        # Update state\n",
        "        super(PixelAccuracyMetric, self).update_state(accuracy)\n",
        "```\n",
        "\n",
        "### 17. Mean Accuracy Metric\n",
        "\n",
        "```python\n",
        "class MeanAccuracyMetric(tf.keras.metrics.Mean):\n",
        "    \"\"\" Mean (class-weighted) accuracy metric \"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes, name='mean_accuracy', **kwargs):\n",
        "        super(MeanAccuracyMetric, self).__init__(name=name, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "    \n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        smooth = 1\n",
        "        \n",
        "        # Set shape and flatten\n",
        "        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "        y_true = tf.reshape(y_true, [-1])\n",
        "        y_pred = tf.reshape(tf.argmax(y_pred, axis=-1), [-1])\n",
        "        \n",
        "        # Create valid mask\n",
        "        valid_mask = tf.reshape((y_true <= self.num_classes - 1), [-1])\n",
        "        y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "        y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "        \n",
        "        # Compute confusion matrix\n",
        "        conf_matrix = tf.cast(\n",
        "            tf.math.confusion_matrix(y_true, y_pred, num_classes=self.num_classes),\n",
        "            'float32'\n",
        "        )\n",
        "        \n",
        "        # Get true positives (diagonal)\n",
        "        true_pos = tf.linalg.diag_part(conf_matrix)\n",
        "        \n",
        "        # Compute mean accuracy\n",
        "        mean_accuracy = tf.reduce_mean(\n",
        "            (true_pos + smooth) / (tf.reduce_sum(conf_matrix, axis=1) + smooth)\n",
        "        )\n",
        "        \n",
        "        # Update state\n",
        "        super(MeanAccuracyMetric, self).update_state(mean_accuracy)\n",
        "```\n",
        "\n",
        "### 18. Mean IoU Metric\n",
        "\n",
        "```python\n",
        "class MeanIoUMetric(tf.keras.metrics.MeanIoU):\n",
        "    \"\"\" Mean Intersection over Union metric \"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes, name='mean_iou', **kwargs):\n",
        "        super(MeanIoUMetric, self).__init__(num_classes=num_classes, name=name, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "    \n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Set shape and flatten\n",
        "        y_true.set_shape([None, y_pred.shape[1], y_pred.shape[2]])\n",
        "        y_true = tf.reshape(y_true, [-1])\n",
        "        y_pred = tf.reshape(tf.argmax(y_pred, axis=-1), [-1])\n",
        "        \n",
        "        # Create valid mask\n",
        "        valid_mask = tf.reshape((y_true <= self.num_classes - 1), [-1])\n",
        "        \n",
        "        # Get pixels corresponding to valid mask\n",
        "        y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "        y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "        \n",
        "        # Update parent state\n",
        "        super(MeanIoUMetric, self).update_state(y_true, y_pred)\n",
        "```\n",
        "\n",
        "### 19. Compile Model\n",
        "\n",
        "```python\n",
        "# Define optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile model\n",
        "deeplabv3.compile(\n",
        "    loss=ce_dice_loss_from_logits(num_classes),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\n",
        "        MeanIoUMetric(num_classes),\n",
        "        MeanAccuracyMetric(num_classes),\n",
        "        PixelAccuracyMetric(num_classes)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Copy weights from original conv5 block\n",
        "w_dict = {}\n",
        "for l in [\"conv5_block1_0_conv\", \"conv5_block1_0_bn\",\n",
        "          \"conv5_block1_1_conv\", \"conv5_block1_1_bn\",\n",
        "          \"conv5_block1_2_conv\", \"conv5_block1_2_bn\",\n",
        "          \"conv5_block1_3_conv\", \"conv5_block1_3_bn\"]:\n",
        "    w_dict[l] = resnet50.get_layer(l).get_weights()\n",
        "\n",
        "# Set weights to new model\n",
        "for l in w_dict:\n",
        "    deeplabv3.get_layer(l).set_weights(w_dict[l])\n",
        "\n",
        "print(\"Model compiled successfully!\")\n",
        "```\n",
        "\n",
        "### 20. Training Model\n",
        "\n",
        "```python\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        'deeplabv3_best.h5',\n",
        "        monitor='val_mean_iou',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_mean_iou',\n",
        "        mode='max',\n",
        "        patience=10,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_mean_iou',\n",
        "        mode='max',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Calculate steps\n",
        "train_steps = 1464 // batch_size  # 1464 training images\n",
        "val_steps = 732 // batch_size     # 732 validation images\n",
        "\n",
        "# Train model\n",
        "history = deeplabv3.fit(\n",
        "    tr_image_ds,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=val_image_ds,\n",
        "    validation_steps=val_steps,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "```\n",
        "\n",
        "### 21. Evaluasi Model\n",
        "\n",
        "```python\n",
        "# Load best model\n",
        "deeplabv3.load_weights('deeplabv3_best.h5')\n",
        "\n",
        "# Evaluate on test set\n",
        "test_steps = 732 // batch_size  # 732 test images\n",
        "test_results = deeplabv3.evaluate(test_image_ds, steps=test_steps)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(f\"Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Mean IoU: {test_results[1]:.4f}\")\n",
        "print(f\"Mean Accuracy: {test_results[2]:.4f}\")\n",
        "print(f\"Pixel Accuracy: {test_results[3]:.4f}\")\n",
        "```\n",
        "\n",
        "### 22. Prediksi dan Visualisasi\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_segmentation(model, image_path, target_path=None):\n",
        "    \"\"\" Visualize segmentation result \"\"\"\n",
        "    \n",
        "    # Load and preprocess image\n",
        "    img = tf.image.decode_jpeg(tf.io.read_file(image_path))\n",
        "    img = tf.image.resize(img, (384, 384))\n",
        "    img_normalized = tf.cast(img, 'float32') / 255.0\n",
        "    img_batch = tf.expand_dims(img_normalized, 0)\n",
        "    \n",
        "    # Predict\n",
        "    pred = model.predict(img_batch)\n",
        "    pred_mask = tf.argmax(pred[0], axis=-1).numpy()\n",
        "    \n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 3 if target_path else 2, figsize=(15, 5))\n",
        "    \n",
        "    axes[0].imshow(img.numpy().astype('uint8'))\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(pred_mask, cmap='tab20')\n",
        "    axes[1].set_title('Predicted Segmentation')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    if target_path:\n",
        "        target = np.array(Image.open(target_path))\n",
        "        target = tf.image.resize(\n",
        "            tf.expand_dims(target, -1),\n",
        "            (384, 384),\n",
        "            method='nearest'\n",
        "        ).numpy().squeeze()\n",
        "        \n",
        "        axes[2].imshow(target, cmap='tab20')\n",
        "        axes[2].set_title('Ground Truth')\n",
        "        axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "test_image = os.path.join(orig_dir, '2007_000033.jpg')\n",
        "test_target = os.path.join(seg_dir, '2007_000033.png')\n",
        "\n",
        "visualize_segmentation(deeplabv3, test_image, test_target)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Kesimpulan\n",
        "\n",
        "Bab 8 ini memberikan penjelasan komprehensif tentang image segmentation dengan fokus pada:\n",
        "\n",
        "1. **Konsep fundamental** segmentasi gambar dan perbedaannya dengan klasifikasi\n",
        "2. **Pipeline data yang efisien** menggunakan tf.data API dengan berbagai optimasi\n",
        "3. **Arsitektur DeepLab v3** yang menggunakan atrous convolution dan ASPP module\n",
        "4. **Loss functions dan metrics** yang specialized untuk tugas segmentasi\n",
        "5. **Implementasi lengkap** dari data loading hingga training dan evaluasi\n",
        "\n",
        "Semua kode di atas dapat dijalankan secara berurutan untuk membuat sistem image segmentation yang lengkap menggunakan dataset PASCAL VOC 2012.\n"
      ],
      "metadata": {
        "id": "HA9Y8FCZLzqh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ScDHA20L2gQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}